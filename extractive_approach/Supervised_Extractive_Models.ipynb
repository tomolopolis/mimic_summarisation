{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datasets import load_metric, load_from_disk\n",
    "from differ import diff_ratio\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 k1897038 users 134320361 Dec 10 17:02 ../mimic_3_val.json\n"
     ]
    }
   ],
   "source": [
    "ls -l ../mimic_3_val.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = pd.read_json('../mimic_3_val.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs.text = all_docs.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove excessively long documents???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs['text_sents'] = all_docs.text.apply(lambda t: [s.text for s in nlp(t).sents  if len(s) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = all_docs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'(?:brief)?\\n?\\s?hospital course:?|SUMMARY OF HOSPITAL COURSE BY SYSTEMS:?', re.IGNORECASE)\n",
    "def clean(s: str):\n",
    "    s = s.replace('\\n\\n' ,'\\n')\\\n",
    "         .replace(r'\\s{2+}', ' ')\\\n",
    "         .replace(r'\\t', ' ')\n",
    "    return pat.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k1897038/anaconda3/envs/medcat/lib/python3.8/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "docs.summary = docs.summary.apply(clean)\n",
    "docs.text = docs.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7588/2063668814.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs['summ_sents'] = docs.summary.apply(lambda t: [s.text for s in nlp(t).sents if len(s) > 3])\n",
      "/tmp/ipykernel_7588/2063668814.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs['text_sents'] = docs.text.apply(lambda t: [s.text for s in nlp(t).sents  if len(s) > 3])\n"
     ]
    }
   ],
   "source": [
    "docs['summ_sents'] = docs.summary.apply(lambda t: [s.text for s in nlp(t).sents if len(s) > 3])\n",
    "docs['text_sents'] = docs.text.apply(lambda t: [s.text for s in nlp(t).sents  if len(s) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:11<00:00,  7.13s/it]\n",
      "/tmp/ipykernel_7588/835971254.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs['text_embed'] = docs.text_sents.progress_apply(lambda sents: [model.encode(s) for s in sents])\n"
     ]
    }
   ],
   "source": [
    "# docs['summ_embed'] = docs.summ_sents.progress_apply(lambda sents: [model.encode(s) for s in sents])\n",
    "docs['text_embed'] = docs.text_sents.progress_apply(lambda sents: [model.encode(s) for s in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc_embeds.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7588/3346329588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc_embeds.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/medcat/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medcat/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc_embeds.pickle'"
     ]
    }
   ],
   "source": [
    "docs = pd.read_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 6 seperate LSTM models for prediciting 'top-line' extractive summaries.\n",
    "sent_limits = [1,2,3,5,10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM embedding model\n",
    "- embeddings are 'fixed' and provided by s-bert (could also be fine-tuned)\n",
    "- (bi-)LSTM ranker on top of sentence embeddings (w/ or w/o attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e27d0b8e07d48ba99f300466e34bcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47951 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_from_disk('/data/users/k1897038/mimic3_dataset_pre_processed')\n",
    "ds = ds.map(lambda d: {'text_embed_len': len(d['text_embed'])})\n",
    "ds = ds.train_test_split(train_size=0.8, test_size=0.2, shuffle=False)\n",
    "val_test_ds = ds['test'].train_test_split(train_size=0.5, test_size=0.5, shuffle=False)\n",
    "train_ds = ds['train']\n",
    "val_ds = val_test_ds['train']\n",
    "test_ds = val_test_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.sort('text_embed_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10 = train_ds[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(s) for s in first_10['text_embed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds['text_sents'][10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds['text_sents_limd'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['hadm_id', 'summary', 'text', 'clean_sum', 'clean_text', 'summ_sents', 'text_sents', 'text_embed', 'summ_lim_1', 'summ_lim_2', 'summ_lim_3', 'summ_lim_5', 'summ_lim_10', 'summ_lim_15', 'text_sents_limd', 'preds_lim_1', 'preds_lim_2', 'preds_lim_3', 'preds_lim_5', 'preds_lim_10', 'preds_lim_15', 'text_embed_len'],\n",
       "    num_rows: 4795\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 384)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_ds['text_embed'][10:11]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_ds.sort('text_embed_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4795"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2,4) + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    foo = (1,3,4)\n",
    "    return foo + (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3836"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(math.ceil(len(val_ds) / bs)):\n",
    "    in_batch = val_ds[i*bs:i*bs + bs]\n",
    "    in_batch_lens = [len(s) for s in in_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest matching sentences from a rouge-Lsum perspective??\n",
    "# model training data is determined by number of sequenecs to extract..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('rouge')\n",
    "# provides 'oracle - rouge2' maximum that can be achieved by the model(s)\n",
    "# for each sent in limited sent summs, find 'closest' matching extractive sentence and mark as 1, all others should be marked as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>summ_sents</th>\n",
       "      <th>text_sents</th>\n",
       "      <th>summ_embed</th>\n",
       "      <th>text_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124571</td>\n",
       "      <td>The patient was transferred to the\\nIntensiv...</td>\n",
       "      <td>Radiology:CHEST (PORTABLE AP)\\n 1)  Possible s...</td>\n",
       "      <td>[The patient was transferred to the\\nIntensive...</td>\n",
       "      <td>[Radiology:CHEST (PORTABLE AP)\\n 1)  , Possibl...</td>\n",
       "      <td>[[-0.034001175, 0.009998081, -0.06825533, -0.0...</td>\n",
       "      <td>[[0.019646827, 0.09096582, -0.016166693, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161919</td>\n",
       "      <td>\\nShe was admitted to ICU for close observatio...</td>\n",
       "      <td>Radiology:CT HEAD W/O CONTRAST\\nKKgc MON [**21...</td>\n",
       "      <td>[\\nShe was admitted to ICU for close observati...</td>\n",
       "      <td>[Radiology:CT HEAD W/O CONTRAST\\n, [**2138-5-1...</td>\n",
       "      <td>[[0.07051655, 0.03656692, 0.036904074, 0.10025...</td>\n",
       "      <td>[[0.07394422, 0.03841625, -0.025370654, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109365</td>\n",
       "      <td>The patient was taken to the operating room\\...</td>\n",
       "      <td>Nursing/other:Report\\nResp Care\\n73 yo admitte...</td>\n",
       "      <td>[The patient was taken to the operating room\\n...</td>\n",
       "      <td>[Nursing/other:Report\\nResp Care\\n73 yo admitt...</td>\n",
       "      <td>[[0.042849362, 0.1184255, -0.07812561, -0.0100...</td>\n",
       "      <td>[[-0.012794435, 0.050156347, -0.011502372, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id                                            summary  \\\n",
       "0   124571    The patient was transferred to the\\nIntensiv...   \n",
       "1   161919  \\nShe was admitted to ICU for close observatio...   \n",
       "2   109365    The patient was taken to the operating room\\...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Radiology:CHEST (PORTABLE AP)\\n 1)  Possible s...   \n",
       "1  Radiology:CT HEAD W/O CONTRAST\\nKKgc MON [**21...   \n",
       "2  Nursing/other:Report\\nResp Care\\n73 yo admitte...   \n",
       "\n",
       "                                          summ_sents  \\\n",
       "0  [The patient was transferred to the\\nIntensive...   \n",
       "1  [\\nShe was admitted to ICU for close observati...   \n",
       "2  [The patient was taken to the operating room\\n...   \n",
       "\n",
       "                                          text_sents  \\\n",
       "0  [Radiology:CHEST (PORTABLE AP)\\n 1)  , Possibl...   \n",
       "1  [Radiology:CT HEAD W/O CONTRAST\\n, [**2138-5-1...   \n",
       "2  [Nursing/other:Report\\nResp Care\\n73 yo admitt...   \n",
       "\n",
       "                                          summ_embed  \\\n",
       "0  [[-0.034001175, 0.009998081, -0.06825533, -0.0...   \n",
       "1  [[0.07051655, 0.03656692, 0.036904074, 0.10025...   \n",
       "2  [[0.042849362, 0.1184255, -0.07812561, -0.0100...   \n",
       "\n",
       "                                          text_embed  \n",
       "0  [[0.019646827, 0.09096582, -0.016166693, -0.01...  \n",
       "1  [[0.07394422, 0.03841625, -0.025370654, -0.029...  \n",
       "2  [[-0.012794435, 0.050156347, -0.011502372, -0....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_limits = [1,2,3,5,10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31791/2000559889.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[f'summ_lim_{lim}'] = docs.summ_sents.apply(lambda sents: sents[:lim])\n"
     ]
    }
   ],
   "source": [
    "sent_limd_sums = defaultdict(list)\n",
    "for lim in sent_limits:\n",
    "    docs[f'summ_lim_{lim}'] = docs.summ_sents.apply(lambda sents: sents[:lim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sent = docs.summ_lim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_score(lvl, scores):\n",
    "    return (lvl, scores[lvl].mid.precision, scores[lvl].mid.recall, scores[lvl].mid.fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31791/3942107128.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[f'preds_lim_{lim}'] = preds_srs\n"
     ]
    }
   ],
   "source": [
    "for lim in sent_limits:\n",
    "    col = f'summ_lim_{lim}'\n",
    "    preds_srs = []\n",
    "    for summ_sents, text_sents in zip(docs[col], docs.text_sents):\n",
    "        sim_text_sent_idxs = []\n",
    "        sents_to_compare = text_sents\n",
    "        for summ_sent in summ_sents:\n",
    "            sents_to_compare = [s if i not in sim_text_sent_idxs else ''\n",
    "                                for i, s in enumerate(text_sents)]\n",
    "            ratios = [diff_ratio(summ_sent, sent)[0] for sent in sents_to_compare]\n",
    "            max_ratio_sents = np.where(ratios == np.amax(ratios))[0]\n",
    "            sim_text_sent_idxs.extend(max_ratio_sents)\n",
    "        preds = np.zeros(len(text_sents))\n",
    "        for i in sim_text_sent_idxs:\n",
    "            preds[i] = 1\n",
    "        preds_srs.append(preds)\n",
    "    docs[f'preds_lim_{lim}'] = preds_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.drop(['summary', 'text', 'summ_embed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max ROUGE scores from 'oracle' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_score(lvl, scores):\n",
    "    return (lvl, scores[lvl].mid.precision, scores[lvl].mid.recall, scores[lvl].mid.fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_score_ceil = {}\n",
    "for lim in sent_limits:\n",
    "    text_sums = []\n",
    "    for sent_idxs, text_sents in zip([np.argwhere(p == 1) for p in docs[f'preds_lim_{lim}']], \n",
    "                                     docs.text_sents):\n",
    "        text_sum = []\n",
    "        for i in sent_idxs:\n",
    "            t = text_sents[i[0]]\n",
    "            if t not in text_sum:\n",
    "                text_sum.append(t)\n",
    "        text_sums.append(''.join(text_sum))\n",
    "    metric.add_batch(predictions=text_sums, references=docs[f'summ_lim_{lim}'].str.join('').tolist())\n",
    "    scores = metric.compute()\n",
    "    extractive_score_ceil[lim] = _parse_score('rouge1', scores), _parse_score('rouge2', scores), _parse_score('rougeLsum', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_score_ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM, Transformer\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f84e00965b0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hadm_id', 'summary', 'text', 'summ_sents', 'text_sents'], dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'text_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7588/3640932858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_embed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_preds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_preds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds_lim_15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/medcat/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'text_embed'"
     ]
    }
   ],
   "source": [
    "inputs = sorted([torch.tensor(t) for t in docs.text_embed], key=lambda t: t.shape[0], reverse=True)\n",
    "outputs = [torch.tensor(d_preds) for d_preds in docs.preds_lim_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lens = [len(i) for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClf, self).__init__()\n",
    "        self.model = LSTM(384, 50, num_layers=2, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, X, X_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lens, batch_first=True)\n",
    "        X, h = self.model(X)\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        X = self.fc(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClf(\n",
       "  (model): LSTM(384, 50, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4540])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:45<00:00, 40.58s/it]\n"
     ]
    }
   ],
   "source": [
    "running_loss = []\n",
    "for epoch in tqdm(range(10)):\n",
    "    logits = model(inputs, in_lens)\n",
    "    loss = criterion(logits.squeeze(), outputs)\n",
    "    loss.backward()\n",
    "    running_loss.append(loss.item())\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    torch.nn.utils.clip_grad_norm_(parameters, 0.25)\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import MimicHospCourseDataset, pad_train_sequence, MimicHospCourseTrainDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer().paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /data/users/k1897038/mimic3_dataset_pre_processed/cache-897443d7d2461d2a.arrow and /data/users/k1897038/mimic3_dataset_pre_processed/cache-78266179c3ef0613.arrow\n",
      "Loading cached sorted indices for dataset at /data/users/k1897038/mimic3_dataset_pre_processed/cache-245bcf82c6035ed0.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = MimicHospCourseTrainDataset(3, size_lim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=10, shuffle=False, collate_fn=pad_sequence, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.ds['hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [b for b in dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs, val_input_lens, input_sents, _, ref_sum_sents = first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first example of mini-batch\n",
    "len(input_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk('/data/users/k1897038/mimic3_dataset_pre_processed/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lstm_model.MimicHospCourseTrainDataset at 0x7f7dac13b340>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /data/users/k1897038/mimic3_dataset_pre_processed/cache-897443d7d2461d2a.arrow and /data/users/k1897038/mimic3_dataset_pre_processed/cache-78266179c3ef0613.arrow\n",
      "Loading cached sorted indices for dataset at /data/users/k1897038/mimic3_dataset_pre_processed/cache-245bcf82c6035ed0.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = MimicHospCourseTrainDataset(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at /data/users/k1897038/mimic3_dataset_pre_processed/cache-15e1a6a432eff442.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = ds.sort('text_embed_len', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_item = ds['text_embed_limd'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = ds.select([0, 1, 2, 3, 4])['text_embed_limd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds.select([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['hadm_id', 'summary', 'text', 'clean_sum', 'clean_text', 'summ_sents', 'text_sents', 'text_embed', 'summ_lim_1', 'summ_lim_2', 'summ_lim_3', 'summ_lim_5', 'summ_lim_10', 'summ_lim_15', 'text_sents_limd', 'preds_lim_1', 'preds_lim_2', 'preds_lim_3', 'preds_lim_5', 'preds_lim_10', 'preds_lim_15', 'text_embed_limd', 'text_embed_len'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trf(d):\n",
    "    pass\n",
    "ds.set_format(trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(train_size=0.8, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['train'].sort('text_embed_len', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format('torch', columns=['text_embed_limd', 'text_embed_len', f'preds_lim_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = first_row['text_embed_limd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[0]['text_embed_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import LSTMClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630601"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44140544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in Transformer().parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('sl3bs100/model_checkpoints/checkpoint--epoch_0-steps_200.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}]}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optim_state_dict': optim.state_dict(),\n",
    "    'epoch': 0,\n",
    "    'batch_skip': 200,\n",
    "}, 'sl3bs100/model_checkpoints/checkpoint--epoch_0-steps_200.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'sl3ds50/model_checkpoints/checkpoint--epoch_9-steps_600.pt'\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optim_state_dict': optim.state_dict(),\n",
    "    'epoch': 10,\n",
    "    'batch_skip':0 \n",
    "}, 'sl3ds50/model_checkpoints/checkpoint--epoch_9-steps_600.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'sl5ds50/model_checkpoints/checkpoint--epoch_4-steps_600.pt'\n",
    "chkpt = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optim_state_dict': optim.state_dict(),\n",
    "    'epoch': 5,\n",
    "    'batch_skip': 600\n",
    "}, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:medcat]",
   "language": "python",
   "name": "conda-env-medcat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
