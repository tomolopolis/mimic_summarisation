{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datasets import load_metric\n",
    "from differ import diff_ratio\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tom/phd/summariser/clin_sum'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = pd.read_json('../mimic_summ_data/mimic_3_val.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs.text = all_docs.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove excessively long documents???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs['text_sents'] = all_docs.text.apply(lambda t: [s.text for s in nlp(t).sents  if len(s) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'(?:brief)?\\n?\\s?hospital course:?|SUMMARY OF HOSPITAL COURSE BY SYSTEMS:?', re.IGNORECASE)\n",
    "def clean(s: str):\n",
    "    s = s.replace('\\n\\n' ,'\\n')\\\n",
    "         .replace(r'\\s{2+}', ' ')\\\n",
    "         .replace(r'\\t', ' ')\n",
    "    return pat.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.summary = docs.summary.apply(clean)\n",
    "docs.text = docs.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      The patient was transferred to the\\nIntensiv...\n",
       "1    \\nShe was admitted to ICU for close observatio...\n",
       "2      The patient was taken to the operating room\\...\n",
       "3      (By systems including pertinent laboratory\\n...\n",
       "4    \\n1. Cardiovascular:  The patient was transfer...\n",
       "5    \\n38 yo male with chronic ACTH dependence, asp...\n",
       "6    \\nASSESSMENT/PLAN [**9-17**]:\\n79 year-old mal...\n",
       "7    \\nPt was admitted and underwent a right pigtai...\n",
       "8    \\n75-year-old man with Burkitt's lymphoma s/p ...\n",
       "9    \\nHe was taken to the operating room on [**10-...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda3/envs/cattrainer/lib/python3.7/site-packages/spacy/util.py:730: UserWarning: [W095] Model 'en_core_web_md' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['summ_sents'] = docs.summary.apply(lambda t: [s.text for s in nlp(t).sents if len(s) > 3])\n",
    "docs['text_sents'] = docs.text.apply(lambda t: [s.text for s in nlp(t).sents  if len(s) > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n",
      "100%|██████████| 10/10 [02:03<00:00, 12.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# docs['summ_embed'] = docs.summ_sents.progress_apply(lambda sents: [model.encode(s) for s in sents])\n",
    "docs['text_embed'] = docs.text_sents.progress_apply(lambda sents: [model.encode(s) for s in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 6 seperate LSTM models for prediciting 'top-line' extractive summaries.\n",
    "sent_limits = [1,2,3,5,10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM embedding model\n",
    "- embeddings are 'fixed' and provided by s-bert (could also be fine-tuned)\n",
    "- (bi-)LSTM ranker on top of sentence embeddings (w/ or w/o attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest matching sentences from a rouge-Lsum perspective??\n",
    "# model training data is determined by number of sequenecs to extract..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('rouge')\n",
    "# provides 'oracle - rouge2' maximum that can be achieved by the model(s)\n",
    "# for each sent in limited sent summs, find 'closest' matching extractive sentence and mark as 1, all others should be marked as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>summ_sents</th>\n",
       "      <th>text_sents</th>\n",
       "      <th>summ_embed</th>\n",
       "      <th>text_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124571</td>\n",
       "      <td>The patient was transferred to the\\nIntensiv...</td>\n",
       "      <td>Radiology:CHEST (PORTABLE AP)\\n 1)  Possible s...</td>\n",
       "      <td>[The patient was transferred to the\\nIntensive...</td>\n",
       "      <td>[Radiology:CHEST (PORTABLE AP)\\n 1)  , Possibl...</td>\n",
       "      <td>[[-0.034001175, 0.009998081, -0.06825533, -0.0...</td>\n",
       "      <td>[[0.019646827, 0.09096582, -0.016166693, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161919</td>\n",
       "      <td>\\nShe was admitted to ICU for close observatio...</td>\n",
       "      <td>Radiology:CT HEAD W/O CONTRAST\\nKKgc MON [**21...</td>\n",
       "      <td>[\\nShe was admitted to ICU for close observati...</td>\n",
       "      <td>[Radiology:CT HEAD W/O CONTRAST\\n, [**2138-5-1...</td>\n",
       "      <td>[[0.07051655, 0.03656692, 0.036904074, 0.10025...</td>\n",
       "      <td>[[0.07394422, 0.03841625, -0.025370654, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109365</td>\n",
       "      <td>The patient was taken to the operating room\\...</td>\n",
       "      <td>Nursing/other:Report\\nResp Care\\n73 yo admitte...</td>\n",
       "      <td>[The patient was taken to the operating room\\n...</td>\n",
       "      <td>[Nursing/other:Report\\nResp Care\\n73 yo admitt...</td>\n",
       "      <td>[[0.042849362, 0.1184255, -0.07812561, -0.0100...</td>\n",
       "      <td>[[-0.012794435, 0.050156347, -0.011502372, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id                                            summary  \\\n",
       "0   124571    The patient was transferred to the\\nIntensiv...   \n",
       "1   161919  \\nShe was admitted to ICU for close observatio...   \n",
       "2   109365    The patient was taken to the operating room\\...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Radiology:CHEST (PORTABLE AP)\\n 1)  Possible s...   \n",
       "1  Radiology:CT HEAD W/O CONTRAST\\nKKgc MON [**21...   \n",
       "2  Nursing/other:Report\\nResp Care\\n73 yo admitte...   \n",
       "\n",
       "                                          summ_sents  \\\n",
       "0  [The patient was transferred to the\\nIntensive...   \n",
       "1  [\\nShe was admitted to ICU for close observati...   \n",
       "2  [The patient was taken to the operating room\\n...   \n",
       "\n",
       "                                          text_sents  \\\n",
       "0  [Radiology:CHEST (PORTABLE AP)\\n 1)  , Possibl...   \n",
       "1  [Radiology:CT HEAD W/O CONTRAST\\n, [**2138-5-1...   \n",
       "2  [Nursing/other:Report\\nResp Care\\n73 yo admitt...   \n",
       "\n",
       "                                          summ_embed  \\\n",
       "0  [[-0.034001175, 0.009998081, -0.06825533, -0.0...   \n",
       "1  [[0.07051655, 0.03656692, 0.036904074, 0.10025...   \n",
       "2  [[0.042849362, 0.1184255, -0.07812561, -0.0100...   \n",
       "\n",
       "                                          text_embed  \n",
       "0  [[0.019646827, 0.09096582, -0.016166693, -0.01...  \n",
       "1  [[0.07394422, 0.03841625, -0.025370654, -0.029...  \n",
       "2  [[-0.012794435, 0.050156347, -0.011502372, -0....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_limd_sums = defaultdict(list)\n",
    "for lim in sent_limits:\n",
    "    docs[f'summ_lim_{lim}'] = docs.summ_sents.apply(lambda sents: sents[:lim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sent = docs.summ_lim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_score(lvl, scores):\n",
    "    return (lvl, scores[lvl].mid.precision, scores[lvl].mid.recall, scores[lvl].mid.fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lim in sent_limits:\n",
    "    col = f'summ_lim_{lim}'\n",
    "    preds_srs = []\n",
    "    for summ_sents, text_sents in zip(docs[col], docs.text_sents):\n",
    "        sim_text_sent_idxs = []\n",
    "        sents_to_compare = text_sents\n",
    "        for summ_sent in summ_sents:\n",
    "            sents_to_compare = [s if i not in sim_text_sent_idxs else ''\n",
    "                                for i, s in enumerate(text_sents)]\n",
    "            ratios = [diff_ratio(summ_sent, sent)[0] for sent in sents_to_compare]\n",
    "            max_ratio_sents = np.where(ratios == np.amax(ratios))[0]\n",
    "            sim_text_sent_idxs.extend(max_ratio_sents)\n",
    "        preds = np.zeros(len(text_sents))\n",
    "        for i in sim_text_sent_idxs:\n",
    "            preds[i] = 1\n",
    "        preds_srs.append(preds)\n",
    "    docs[f'preds_lim_{lim}'] = preds_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.drop(['summary', 'text', 'summ_embed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_pickle('doc_embeds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max ROUGE scores from 'oracle' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_score(lvl, scores):\n",
    "    return (lvl, scores[lvl].mid.precision, scores[lvl].mid.recall, scores[lvl].mid.fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_score_ceil = {}\n",
    "for lim in sent_limits:\n",
    "    text_sums = []\n",
    "    for sent_idxs, text_sents in zip([np.argwhere(p == 1) for p in docs[f'preds_lim_{lim}']], \n",
    "                                     docs.text_sents):\n",
    "        text_sum = []\n",
    "        for i in sent_idxs:\n",
    "            t = text_sents[i[0]]\n",
    "            if t not in text_sum:\n",
    "                text_sum.append(t)\n",
    "        text_sums.append(''.join(text_sum))\n",
    "    metric.add_batch(predictions=text_sums, references=docs[f'summ_lim_{lim}'].str.join('').tolist())\n",
    "    scores = metric.compute()\n",
    "    extractive_score_ceil[lim] = _parse_score('rouge1', scores), _parse_score('rouge2', scores), _parse_score('rougeLsum', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_score_ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f81d1716fa8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sorted([torch.tensor(t) for t in docs.text_embed], key=lambda t: t.shape[0], reverse=True)\n",
    "outputs = [torch.tensor(d_preds) for d_preds in docs.preds_lim_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lens = [len(i) for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClf, self).__init__()\n",
    "        self.model = LSTM(384, 50, num_layers=2, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, X, X_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lens, batch_first=True)\n",
    "        X, h = self.model(X)\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        X = self.fc(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClf(\n",
       "  (model): LSTM(384, 50, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4540])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:45<00:00, 40.58s/it]\n"
     ]
    }
   ],
   "source": [
    "running_loss = []\n",
    "for epoch in tqdm(range(10)):\n",
    "    logits = model(inputs, in_lens)\n",
    "    loss = criterion(logits.squeeze(), outputs)\n",
    "    loss.backward()\n",
    "    running_loss.append(loss.item())\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    torch.nn.utils.clip_grad_norm_(parameters, 0.25)\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7510637823484083,\n",
       " 0.6069032915121987,\n",
       " 0.5673535308240203,\n",
       " 0.5310154317266057,\n",
       " 0.4953841878154565,\n",
       " 0.4625271369234581,\n",
       " 0.43124800153486925,\n",
       " 0.4020194065181891,\n",
       " 0.3748356447783237,\n",
       " 0.3489772009557433]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cattrainer]",
   "language": "python",
   "name": "conda-env-cattrainer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
